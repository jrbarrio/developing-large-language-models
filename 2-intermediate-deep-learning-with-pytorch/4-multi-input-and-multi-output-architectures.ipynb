{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-input models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniglotDataset(Dataset):\n",
    "  def __init__(self, transform, samples):\n",
    "    self.transform = transform\n",
    "    self.samples = samples\n",
    "                  \n",
    "  def __len__(self):\n",
    "    return len(self.samples)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    img_path, alphabet, label = self.samples[idx]\n",
    "    img = Image.open(img_path).convert('L')\n",
    "    img_transformed = self.transform(img)\n",
    "    return img_transformed, alphabet, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.image_layer = nn.Sequential(\n",
    "      nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "      nn.MaxPool2d(kernel_size=2),\n",
    "      nn.ELU(),\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(16*32*32, 128)\n",
    "    )\n",
    "    self.alphabet_layer = nn.Sequential(\n",
    "      nn.Linear(30, 8),\n",
    "      nn.ELU(), \n",
    "    )\n",
    "    self.classifier = nn.Sequential(\n",
    "      nn.Linear(128 + 8, 964), \n",
    "    )\n",
    "      \n",
    "  def forward(self, x_image, x_alphabet):\n",
    "    x_image = self.image_layer(x_image)\n",
    "    x_alphabet = self.alphabet_layer(x_alphabet)\n",
    "    x = torch.cat((x_image, x_alphabet), dim=1)\n",
    "    return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-output DataSet and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples[100])\n",
    "\n",
    "dataset_train = OmniglotDataset(\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "      \ttransforms.Resize((64, 64)),\n",
    "    ]),\n",
    "    samples=samples,\n",
    ")\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "  dataset_train, shuffle=True, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-output model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.image_layer = nn.Sequential(\n",
    "      nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "      nn.MaxPool2d(kernel_size=2),\n",
    "      nn.ELU(),\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(16*32*32, 128)\n",
    "    )\n",
    "    self.classifier_alpha = nn.Linear(128, 30)\n",
    "    self.classifier_char = nn.Linear(128, 964)\n",
    "      \n",
    "  def forward(self, x):\n",
    "    x_image = self.image_layer(x)\n",
    "    output_alpha = self.classifier_alpha(x_image)\n",
    "    output_char = self.classifier_char(x_image)\n",
    "    return output_alpha, output_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training multi-output model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.05)\n",
    "\n",
    "for epoch in range(1):\n",
    "  for images, labels_alpha, labels_char in dataloader_train:\n",
    "    optimizer.zero_grad()\n",
    "    outputs_alpha, outputs_char = net(images)\n",
    "    loss_alpha = criterion(outputs_alpha, labels_alpha)\n",
    "    loss_char = criterion(outputs_char, labels_char)\n",
    "    loss = loss_alpha + loss_char\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of multi-output models and loss weighting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-output evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "  acc_alpha = Accuracy(task=\"multiclass\", num_classes=30)\n",
    "  acc_char = Accuracy(task=\"multiclass\", num_classes=964)\n",
    "\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for images, labels_alpha, labels_char in dataloader_test:\n",
    "      outputs_alpha, outputs_char = model(images)\n",
    "      _, pred_alpha = torch.max(outputs_alpha, 1)\n",
    "      _, pred_char = torch.max(outputs_char, 1)\n",
    "      acc_alpha(pred_alpha, labels_alpha)\n",
    "      acc_char(pred_char, labels_char)\n",
    "  \n",
    "  print(f\"Alphabet: {acc_alpha.compute()}\")\n",
    "  print(f\"Character: {acc_char.compute()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-in-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
